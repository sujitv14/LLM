# -*- coding: utf-8 -*-
"""Untitled30.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12VtbWHXqfL51cKGBOxdH90Yulsfcf8ND
"""

import streamlit as st
from langchain import OpenAI, LLMChain
from langchain.prompts import PromptTemplate
import os

# Set your OpenAI API key
os.environ["OPENAI_API_KEY"] = "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"

# Define your LangChain app
prompt_template = "You are a helpful assistant. Answer the question: {question}"
prompt = PromptTemplate(template=prompt_template, input_variables=["question"])

# llm = OpenAI(model="text-davinci-003")
llm = OpenAI(model="gpt-3.5-turbo")
# llm = OpenAI(model_kwargs={"model": "gpt-3.5-turbo"})
llm_chain = LLMChain(llm=llm, prompt=prompt)

st.title("LangChain App")
question = st.text_input("Enter your question:")
if question:
    response = llm_chain.run({"question": question})
    st.write(f"Response: {response}")